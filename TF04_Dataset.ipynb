{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow implementation 04: Dataset\n",
    "\n",
    "by [Sho Nakagome](https://github.com/shonaka)\n",
    "\n",
    "This jupyter notebook is intended to implement demonstrate tensorflow's data API. More specifically, about tf.data.Dataset API.\n",
    "\n",
    "The link to official document is [here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset). A simple explanation to this API is that it allows you to handle data more easily using tensorflow. For example, if you have a very large dataset that you cannot fit into your memory at once, this API let you create a data loading flow (with preprocessing and augmentations if you want) so that you can handle enormous amount of data with ease.\n",
    "\n",
    "In this demonstration, I'm using a dataset from one of the competitions in [kaggle](https://www.kaggle.com/c/plant-seedlings-classification). Note that I'm finishing this notebook until running a classification task using CNN but the model is very simple one. Also, there's no optimization performed so don't worry if the performance is low for now, we'll get to it in the later notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "# Just for visualization in jupyter notebook purposes\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming environment: Python 3.6 (Anaconda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables\n",
    "\n",
    "Let's define some global variables to be used in the code. Don't worry about this for now since we will be describing these in the later part of the notebooks when these appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RNN related\n",
    "NUM_HIDDEN = 32  # Number of hidden units in a hidden layer\n",
    "\n",
    "# Optimization related\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 32  # Better to have a batch size 2^n\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and checking the dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
